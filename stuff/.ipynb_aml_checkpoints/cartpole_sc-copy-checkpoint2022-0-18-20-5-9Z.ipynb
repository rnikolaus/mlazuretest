{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Prerequisite\n",
        "The user should have completed the Azure Machine Learning Tutorial: [Get started creating your first ML experiment with the Python SDK](https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-1st-experiment-sdk-setup). You will need to make sure that you have a valid subscription ID, a resource group, and an Azure Machine Learning workspace. All datastores and datasets you use should be associated with your workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up Development Environment\n",
        "The following subsections show typical steps to setup your development environment. Setup includes:\n",
        "\n",
        "* Connecting to a workspace to enable communication between your local machine and remote resources\n",
        "* Creating an experiment to track all your runs\n",
        "* Creating a remote compute target to use for training"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Azure Machine Learning SDK \n",
        "Display the Azure Machine Learning SDK version."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "\n",
        "print(\"Azure Machine Learning SDK Version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Azure Machine Learning SDK Version: 1.36.0\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1642456790317
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Azure Machine Learning workspace\n",
        "Get a reference to an existing Azure Machine Learning workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.location, ws.resource_group, sep = ' | ')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ml-workspace | eastus | ml-rg\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1642456796792
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a new compute resource or attach an existing one\n",
        "\n",
        "A compute target is a designated compute resource where you run your training and simulation scripts. This location may be your local machine or a cloud-based compute resource. The code below shows how to create a cloud-based compute target. For more information see [What are compute targets in Azure Machine Learning?](https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target)\n",
        "\n",
        "> Note that if you have an AzureML Data Scientist role, you will not have permission to create compute resources. Talk to your workspace or IT admin to create the compute targets described in this section, if they do not already exist.\n",
        "\n",
        "**Note: Creation of a compute resource can take several minutes**. Please make sure to change `STANDARD_D2_V2` to a [size available in your region](https://azure.microsoft.com/en-us/global-infrastructure/services/?products=virtual-machines)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AmlCompute, ComputeTarget\n",
        "import os\n",
        "\n",
        "# Choose a name and maximum size for your cluster\n",
        "compute_name = \"cpu-cluster-d2\"\n",
        "compute_min_nodes = 0\n",
        "compute_max_nodes = 4\n",
        "vm_size = \"STANDARD_D2_V2\"\n",
        "\n",
        "if compute_name in ws.compute_targets:\n",
        "    print(\"Found an existing compute target of name: \" + compute_name)\n",
        "    compute_target = ws.compute_targets[compute_name]\n",
        "    # Note: you may want to make sure compute_target is of type AmlCompute        \n",
        "else:\n",
        "    print(\"Creating new compute target...\")\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(\n",
        "        vm_size=vm_size,\n",
        "        min_nodes=compute_min_nodes, \n",
        "        max_nodes=compute_max_nodes)\n",
        "        \n",
        "    # Create the cluster\n",
        "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
        "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
        "\n",
        "print(compute_target.get_status().serialize())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found an existing compute target of name: cpu-cluster-d2\n{'currentNodeCount': 1, 'targetNodeCount': 1, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 1, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2022-01-17T18:10:34.433000+00:00', 'errors': None, 'creationTime': '2022-01-15T14:45:39.283011+00:00', 'modifiedTime': '2022-01-15T14:45:42.951037+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT1800S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D2_V2'}\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1642456810230
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Azure Machine Learning experiment\n",
        "Create an experiment to track the runs in your workspace. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.experiment import Experiment\n",
        "\n",
        "from files import BCTrade_utils\n",
        "env ='Btc_with_indicators'\n",
        "experiment_name = BCTrade_utils.registerBCTrade(env)\n",
        "exp = Experiment(workspace=ws, name=experiment_name)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1642456819376
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Cartpole Agent\n",
        "To facilitate reinforcement learning, Azure Machine Learning Python SDK provides a high level abstraction, the _ReinforcementLearningEstimator_ class, which allows users to easily construct reinforcement learning run configurations for the underlying reinforcement learning framework. Reinforcement Learning in Azure Machine Learning supports the open source [Ray framework](https://ray.io/) and its highly customizable [RLlib](https://ray.readthedocs.io/en/latest/rllib.html#rllib-scalable-reinforcement-learning). In this section we show how to use _ReinforcementLearningEstimator_ and Ray/RLlib framework to train a cartpole playing agent. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create reinforcement learning estimator\n",
        "\n",
        "The code below creates an instance of *ReinforcementLearningEstimator*, `training_estimator`, which then will be used to submit a job to Azure Machine Learning to start the Ray experiment run.\n",
        "\n",
        "Note that this example is purposely simplified to the minimum. Here is a short description of the parameters we are passing into the constructor:\n",
        "\n",
        "- `source_directory`, local directory containing your training script(s) and helper modules,\n",
        "- `entry_script`, path to your entry script relative to the source directory,\n",
        "- `script_params`, constant parameters to be passed to each run of training script,\n",
        "- `compute_target`, reference to the compute target in which the trainer and worker(s) jobs will be executed,\n",
        "- `rl_framework`, the reinforcement learning framework to be used (currently must be Ray).\n",
        "\n",
        "We use the `script_params` parameter to pass in general and algorithm-specific parameters to the training script.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.contrib.train.rl import ReinforcementLearningEstimator, Ray\n",
        "from azureml.core.environment import Environment\n",
        "\n",
        "training_algorithm = \"PPO\"\n",
        "rl_environment = env\n",
        "video_capture = False\n",
        "\n",
        "algorithm_config = '\\'{\"num_gpus\": 0, \"num_workers\": 1}\\''\n",
        "#if video_capture:\n",
        "#    algorithm_config = '\\'{\"num_gpus\": 0, \"num_workers\": 1, \"monitor\": true}\\''\n",
        "#else:\n",
        "#    algorithm_config = '\\'{\"num_gpus\": 0, \"num_workers\": 1, \"monitor\": false}\\''\n",
        "\n",
        "script_params = {\n",
        "\n",
        "    # Training algorithm\n",
        "    \"--run\": training_algorithm,\n",
        "    \n",
        "    # Training environment\n",
        "    \"--env\": rl_environment,\n",
        "    \n",
        "    # Algorithm-specific parameters\n",
        "    \"--config\": algorithm_config,\n",
        "    \n",
        "    # Stop conditions\n",
        "    \"--stop\": '\\'{\"episode_reward_mean\": 200, \"time_total_s\": 36000}\\'',\n",
        "    \n",
        "    # Frequency of taking checkpoints\n",
        "    \"--checkpoint-freq\": 1,\n",
        "    \n",
        "    # If a checkpoint should be taken at the end - optional argument with no value\n",
        "    \"--checkpoint-at-end\": \"\",\n",
        "    \n",
        "    # Log directory\n",
        "    \"--local-dir\": './logs'\n",
        "}\n",
        "\n",
        "xvfb_env = None\n",
        "#if video_capture:\n",
        "    # Ray's video capture support requires to run everything under a headless display driver called (xvfb).\n",
        "    # There are two parts to this:\n",
        "    # 1. Use a custom docker file with proper instructions to install xvfb, ffmpeg, python-opengl\n",
        "    # and other dependencies.\n",
        "   \n",
        "#    with open(\"files/docker/Dockerfile\", \"r\") as f:\n",
        "#        dockerfile=f.read()\n",
        "\n",
        "#    xvfb_env = Environment(name='xvfb-vdisplay')\n",
        "#    xvfb_env.docker.base_image = None\n",
        "#    xvfb_env.docker.base_dockerfile = dockerfile\n",
        "    \n",
        "    # 2.  Execute the Python process via the xvfb-run command to set up the headless display driver.\n",
        "#    xvfb_env.python.user_managed_dependencies = True\n",
        "#    xvfb_env.python.interpreter_path = \"xvfb-run -s '-screen 0 640x480x16 -ac +extension GLX +render' python\"\n",
        "\n",
        "\n",
        "training_estimator = ReinforcementLearningEstimator(\n",
        "\n",
        "    # Location of source files\n",
        "    source_directory='files',\n",
        "    \n",
        "    # Python script file\n",
        "    entry_script='BCTrade_training.py',\n",
        "    \n",
        "    # A dictionary of arguments to pass to the training script specified in ``entry_script``\n",
        "    script_params=script_params,\n",
        "    \n",
        "    # The Azure Machine Learning compute target set up for Ray head nodes\n",
        "    compute_target=compute_target,\n",
        "    \n",
        "    # Reinforcement learning framework. Currently must be Ray.\n",
        "    rl_framework=Ray(),\n",
        "    \n",
        "    # Custom environmnet for Xvfb\n",
        "    environment=xvfb_env\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1642456827324
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training script\n",
        "\n",
        "As recommended in RLlib documentations, we use Ray Tune API to run the training algorithm. All the RLlib built-in trainers are compatible with the Tune API. Here we use `tune.run()` to execute a built-in training algorithm. For convenience, down below you can see part of the entry script where we make this call.\n",
        "\n",
        "This is the list of parameters we are passing into `tune.run()` via the `script_params` parameter:\n",
        "\n",
        "- `run_or_experiment`: name of the [built-in algorithm](https://ray.readthedocs.io/en/latest/rllib-algorithms.html#rllib-algorithms), 'PPO' in our example,\n",
        "- `config`: Algorithm-specific configuration. This includes specifying the environment, `env`, which in our example is the gym **[CartPole-v0](https://gym.openai.com/envs/CartPole-v0/)** environment,\n",
        "- `stop`: stopping conditions, which could be any of the metrics returned by the trainer. Here we use \"mean of episode reward\", and \"total training time in seconds\" as stop conditions, and\n",
        "- `checkpoint_freq` and `checkpoint_at_end`: Frequency of taking checkpoints (number of training iterations between checkpoints), and if a checkpoint should be taken at the end.\n",
        "\n",
        "We also specify the `local_dir`, the directory in which the training logs, checkpoints and other training artificats will be recorded. \n",
        "\n",
        "See [RLlib Training APIs](https://ray.readthedocs.io/en/latest/rllib-training.html#rllib-training-apis) for more details, and also [Training (tune.run, tune.Experiment)](https://ray.readthedocs.io/en/latest/tune/api_docs/execution.html#training-tune-run-tune-experiment) for the complete list of parameters.\n",
        "\n",
        "```python\n",
        "import ray\n",
        "import ray.tune as tune\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # parse arguments ...\n",
        "    \n",
        "    # Intitialize ray\n",
        "    ray.init(address=args.ray_address)\n",
        "\n",
        "    # Run training task using tune.run\n",
        "    tune.run(\n",
        "        run_or_experiment=args.run,\n",
        "        config=dict(args.config, env=args.env),\n",
        "        stop=args.stop,\n",
        "        checkpoint_freq=args.checkpoint_freq,\n",
        "        checkpoint_at_end=args.checkpoint_at_end,\n",
        "        local_dir=args.local_dir\n",
        "    )\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submit the estimator to start experiment\n",
        "Now we use the *training_estimator* to submit a run."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "training_run = exp.submit(training_estimator)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1642456844116
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Monitor experiment\n",
        "\n",
        "Azure Machine Learning provides a Jupyter widget to show the status of an experiment run. You could use this widget to monitor the status of the runs.\n",
        "\n",
        "Note that _ReinforcementLearningEstimator_ creates at least two runs: (a) A parent run, i.e. the run returned above, and (b) a collection of child runs. The number of the child runs depends on the configuration of the reinforcement learning estimator. In our simple scenario, configured above, only one child run will be created.\n",
        "\n",
        "The widget will show a list of the child runs as well. You can click on the link under **Status** to see the details of a child run. It will also show the metrics being logged."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "\n",
        "RunDetails(training_run).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_RLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'sdk_v…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d26f85550e9748b3aa97d84a5855de44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/BCTrade-Btc_with_indicators_1642456841_23aa4433?wsid=/subscriptions/736ac584-c533-43a9-8a83-d19bf290ffb8/resourcegroups/ml-rg/workspaces/ml-workspace&tid=3ffbf2df-6ac2-41dc-95c5-2f64a8024caf\", \"run_id\": \"BCTrade-Btc_with_indicators_1642456841_23aa4433\", \"run_properties\": {\"run_id\": \"BCTrade-Btc_with_indicators_1642456841_23aa4433\", \"created_utc\": \"2022-01-17T22:00:43.620816Z\", \"properties\": {}, \"tags\": {}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"azureml-logs/reinforcementlearning.txt\": \"https://rnikolaus.blob.core.windows.net/azureml/ExperimentRun/dcid.BCTrade-Btc_with_indicators_1642456841_23aa4433/azureml-logs/reinforcementlearning.txt?sv=2019-07-07&sr=b&sig=%2FDPkGm9XJ8Foguqf61IA%2BYyNpNBGvgeb4E6eKT%2F40QU%3D&skoid=e2479b93-fc73-41fb-89ce-5cfc3e486410&sktid=3ffbf2df-6ac2-41dc-95c5-2f64a8024caf&skt=2022-01-17T19%3A59%3A06Z&ske=2022-01-19T04%3A09%3A06Z&sks=b&skv=2019-07-07&st=2022-01-17T21%3A56%3A04Z&se=2022-01-18T06%3A06%3A04Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/reinforcementlearning.txt\"]], \"run_duration\": \"0:06:08\", \"run_number\": \"44\", \"run_queued_details\": {\"status\": \"Running\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"BCTrade-Btc_with_indicators_1642456841_23aa4433_head\", \"run_number\": 45, \"metric\": null, \"status\": \"Running\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2022-01-17T22:01:05.705883Z\", \"end_time\": \"\", \"created_time\": \"2022-01-17T22:00:50.755932Z\", \"created_time_dt\": \"2022-01-17T22:00:50.755932Z\", \"duration\": \"0:06:01\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2022-01-17T22:00:43.6955527Z][Info]Starting reinforcement learning run with id BCTrade-Btc_with_indicators_1642456841_23aa4433.\\n[2022-01-17T22:00:49.5821856Z][Info]Starting head node child run with id BCTrade-Btc_with_indicators_1642456841_23aa4433_head.\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.36.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1642456855500
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stop the run\n",
        "To stop the run, call `training_run.cancel()`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment line below to cancel the run\n",
        "training_run.cancel()"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1642185981812
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wait for completion\n",
        "Wait for the run to complete before proceeding.\n",
        "\n",
        "**Note: The length of the run depends on the provisioning time of the compute target and it may take several minutes to complete.**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "training_run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "{'runId': 'BCTrade_1640902113_16a527ae',\n 'status': 'Canceled',\n 'startTimeUtc': '2021-12-30T22:12:38.723146Z',\n 'endTimeUtc': '2021-12-30T22:39:29.407457Z',\n 'services': {},\n 'properties': {},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'logFiles': {'azureml-logs/reinforcementlearning.txt': 'https://rnikolaus.blob.core.windows.net/azureml/ExperimentRun/dcid.BCTrade_1640902113_16a527ae/azureml-logs/reinforcementlearning.txt?sv=2019-07-07&sr=b&sig=WU%2Bsv43vLY46T5273bVk%2BQFgOfDgHwLC%2FTHYTup%2B2cE%3D&skoid=e2479b93-fc73-41fb-89ce-5cfc3e486410&sktid=3ffbf2df-6ac2-41dc-95c5-2f64a8024caf&skt=2021-12-30T12%3A24%3A57Z&ske=2021-12-31T20%3A34%3A57Z&sks=b&skv=2019-07-07&st=2021-12-30T22%3A25%3A05Z&se=2021-12-31T06%3A35%3A05Z&sp=r'},\n 'submittedBy': 'Raphael Nikolaus'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1640903970295
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get a handle to the child run\n",
        "You can obtain a handle to the child run as follows. In our scenario, there is only one child run, we have it called `child_run_0`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "child_run_0 = None\n",
        "timeout = 30\n",
        "while timeout > 0 and not child_run_0:\n",
        "    child_runs = list(training_run.get_children())\n",
        "    print('Number of child runs:', len(child_runs))\n",
        "    if len(child_runs) > 0:\n",
        "        child_run_0 = child_runs[0]\n",
        "        break\n",
        "    time.sleep(2) # Wait for 2 seconds\n",
        "    timeout -= 2\n",
        "\n",
        "print('Child run info:')\n",
        "print(child_run_0)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'training_run' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-cca776bce925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchild_run_0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mchild_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of child runs:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_run' is not defined"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1641755817545
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get access to training artifacts\n",
        "We can simply use run id to get a handle to an in-progress or a previously concluded run."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Run\n",
        "\n",
        "#run_id = child_run_0.id # Or set to run id of a completed run (e.g. 'rl-cartpole-v0_1587572312_06e04ace_head')\n",
        "run_id = 'BCTrade-Btc_with_indicators_1642358881_a646c5f3_head'\n",
        "child_run_0 = Run(exp, run_id=run_id)\n",
        "#child_run_0.get_environment()"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1642401275206
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can use the Run API to download policy training artifacts (saved model and checkpoints) to local compute."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from distutils import dir_util\n",
        "\n",
        "training_artifacts_path = path.join(\"logs\", training_algorithm)\n",
        "print(\"Training artifacts path:\", training_artifacts_path)\n",
        "\n",
        "if path.exists(training_artifacts_path):\n",
        "    dir_util.remove_tree(training_artifacts_path)\n",
        "\n",
        "# Download run artifacts to local compute\n",
        "child_run_0.download_files(training_artifacts_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training artifacts path: logs/PPO\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1642401285949
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Trained Agent and See Results\n",
        "\n",
        "We can evaluate a previously trained policy using the `rollout.py` helper script provided by RLlib (see [Evaluating Trained Policies](https://ray.readthedocs.io/en/latest/rllib-training.html#evaluating-trained-policies) for more details). Here we use an adaptation of this script to reconstruct a policy from a checkpoint taken and saved during training. We took these checkpoints by setting `checkpoint-freq` and `checkpoint-at-end` parameters above.\n",
        "In this section we show how to use these checkpoints to evaluate the trained policy."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate a trained policy\n",
        "We need to configure another reinforcement learning estimator, `rollout_estimator`, and then use it to submit another run. Note that the entry script for this estimator now points to `cartpole-rollout.py` script.\n",
        "Also note how we pass the checkpoints dataset to this script using `inputs` parameter of the _ReinforcementLearningEstimator_.\n",
        "\n",
        "We are using script parameters to pass in the same algorithm and the same environment used during training. We also specify the checkpoint number of the checkpoint we wish to evaluate, `checkpoint-number`, and number of the steps we shall run the rollout, `steps`.\n",
        "\n",
        "The training artifacts dataset will be accessible to the rollout script as a mounted folder. The mounted folder and the checkpoint number, passed in via `checkpoint-number`, will be used to create a path to the checkpoint we are going to evaluate. The created checkpoint path then will be passed into RLlib rollout script for evaluation.\n",
        "\n",
        "Let's find the checkpoints and the last checkpoint number first."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# A helper function to find checkpoint files in a directory\n",
        "def find_checkpoints(file_path):\n",
        "    print(\"Looking in path:\", file_path)\n",
        "    checkpoints = []\n",
        "    for root, _, files in os.walk(file_path):\n",
        "        for name in files:\n",
        "            if os.path.basename(root).startswith('checkpoint_'):\n",
        "                checkpoints.append(path.join(root, name))\n",
        "    return checkpoints\n",
        "\n",
        "checkpoint_files = find_checkpoints(training_artifacts_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Looking in path: logs/PPO\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1642401296622
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find checkpoints and last checkpoint number\n",
        "checkpoint_numbers = []\n",
        "for file in checkpoint_files:\n",
        "    file = os.path.basename(file)\n",
        "    if file.startswith('checkpoint-') and not file.endswith('.tune_metadata'):\n",
        "        checkpoint_numbers.append(int(file.split('-')[-1]))\n",
        "\n",
        "print(\"Checkpoints:\", checkpoint_numbers)\n",
        "\n",
        "last_checkpoint_number = max(checkpoint_numbers)\n",
        "print(\"Last checkpoint number:\", last_checkpoint_number)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Checkpoints: [1908, 888, 889, 896, 897, 898, 899, 900, 901, 902, 903]\nLast checkpoint number: 1908\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1642401300240
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the checkpoint files and create a DataSet\n",
        "from azureml.core import Dataset\n",
        "\n",
        "datastore = ws.get_default_datastore()\n",
        "checkpoint_dataref = datastore.upload_files(checkpoint_files, target_path='checkpoints_' + run_id, overwrite=True)\n",
        "checkpoint_ds = Dataset.File.from_files(checkpoint_dataref)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading an estimated of 22 files\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_1058/checkpoint-1058\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_1058/checkpoint-1058, 1 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_1058/checkpoint-1058.tune_metadata\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_1058/checkpoint-1058.tune_metadata, 2 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_2107/checkpoint-2107\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_2107/checkpoint-2107, 3 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_2107/checkpoint-2107.tune_metadata\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_2107/checkpoint-2107.tune_metadata, 4 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_230/checkpoint-230\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_230/checkpoint-230, 5 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_230/checkpoint-230.tune_metadata\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_230/checkpoint-230.tune_metadata, 6 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_232/checkpoint-232.tune_metadata\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_232/checkpoint-232.tune_metadata, 7 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_234/checkpoint-234\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_234/checkpoint-234, 8 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_234/checkpoint-234.tune_metadata\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_234/checkpoint-234.tune_metadata, 9 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_236/checkpoint-236.tune_metadata\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_236/checkpoint-236.tune_metadata, 10 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_238/checkpoint-238.tune_metadata\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_238/checkpoint-238.tune_metadata, 11 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_240/checkpoint-240\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_240/checkpoint-240, 12 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_240/checkpoint-240.tune_metadata\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_240/checkpoint-240.tune_metadata, 13 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_256/checkpoint-256.tune_metadata\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_256/checkpoint-256.tune_metadata, 14 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_258/checkpoint-258.tune_metadata\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_258/checkpoint-258.tune_metadata, 15 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_268/checkpoint-268\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_268/checkpoint-268, 16 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_268/checkpoint-268.tune_metadata\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_268/checkpoint-268.tune_metadata, 17 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_232/checkpoint-232\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_232/checkpoint-232, 18 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_236/checkpoint-236\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_236/checkpoint-236, 19 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_238/checkpoint-238\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_238/checkpoint-238, 20 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_256/checkpoint-256\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_256/checkpoint-256, 21 files out of an estimated total of 22\nUploading logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_258/checkpoint-258\nUploaded logs/PPO/PPO_BCTrade-Btc_with_indicators_15c725a4_2022-01-16_07-36-57huo0c0ro/checkpoint_258/checkpoint-258, 22 files out of an estimated total of 22\nUploaded 22 files\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1642356365957
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's configure rollout estimator. Note that we use the last checkpoint for evaluation. The assumption is that the last checkpoint points to our best trained agent. You may change this to any of the checkpoint numbers printed above and observe the effect."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "script_params = {    \n",
        "    # Checkpoint number of the checkpoint from which to roll out\n",
        "    \"--checkpoint-number\": last_checkpoint_number,\n",
        "\n",
        "    # Training algorithm\n",
        "    \"--run\": training_algorithm,\n",
        "    \n",
        "    # Training environment\n",
        "    \"--env\": rl_environment,\n",
        "    \n",
        "    # Algorithm-specific parameters\n",
        "    \"--config\": '{}',\n",
        "    \n",
        "    # Number of rollout steps \n",
        "    \"--steps\": 2000,\n",
        "    \n",
        "    # If should repress rendering of the environment\n",
        "    \"--no-render\": \"\",\n",
        "    \n",
        "    # The place where recorded videos will be stored\n",
        "    \"--video-dir\": \"./logs/video\"\n",
        "}\n",
        "\n",
        "if video_capture:\n",
        "    script_params.pop(\"--no-render\")\n",
        "else:\n",
        "    script_params.pop(\"--video-dir\")\n",
        "\n",
        "\n",
        "# Ray's video capture support requires to run everything under a headless display driver called (xvfb).\n",
        "# There are two parts to this:\n",
        "\n",
        "# 1. Use a custom docker file with proper instructions to install xvfb, ffmpeg, python-opengl\n",
        "# and other dependencies.\n",
        "# Note: Even when the rendering is off pyhton-opengl is needed.\n",
        "\n",
        "#with open(\"files/docker/Dockerfile\", \"r\") as f:\n",
        "#    dockerfile=f.read()\n",
        "\n",
        "#xvfb_env = Environment(name='xvfb-vdisplay')\n",
        "#xvfb_env.docker.base_image = None\n",
        "#xvfb_env.docker.base_dockerfile = dockerfile\n",
        "    \n",
        "# 2.  Execute the Python process via the xvfb-run command to set up the headless display driver.\n",
        "#xvfb_env.python.user_managed_dependencies = True\n",
        "#if video_capture:\n",
        "#    xvfb_env.python.interpreter_path = \"xvfb-run -s '-screen 0 640x480x16 -ac +extension GLX +render' python\"\n",
        "\n",
        "\n",
        "rollout_estimator = ReinforcementLearningEstimator(\n",
        "    # Location of source files\n",
        "    source_directory='files',\n",
        "    \n",
        "    # Python script file\n",
        "    entry_script='BCTrade_rollout.py',\n",
        "    \n",
        "    # A dictionary of arguments to pass to the rollout script specified in ``entry_script``\n",
        "    script_params = script_params,\n",
        "    \n",
        "    # Data inputs\n",
        "    inputs=[\n",
        "        checkpoint_ds.as_named_input('artifacts_dataset'),\n",
        "        checkpoint_ds.as_named_input('artifacts_path').as_mount()],\n",
        "    \n",
        "    # The Azure Machine Learning compute target set up for Ray head nodes\n",
        "    compute_target=compute_target,\n",
        "    \n",
        "    # Reinforcement learning framework. Currently must be Ray.\n",
        "    rl_framework=Ray(),\n",
        "    \n",
        "    # Custom environmnet for Xvfb\n",
        "    environment=xvfb_env)"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1641756018574
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same as before, we use the *rollout_estimator* to submit a run."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "rollout_run = exp.submit(rollout_estimator)"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1641756036817
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then, similar to the training section, we can monitor the real-time progress of the rollout run and its chid as follows. If you browse logs of the child run you can see the evaluation results recorded in driver_log.txt file. Note that you may need to wait several minutes before these results become available."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(rollout_run).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_RLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'sdk_v…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82b66e8a80e549e9962018298af4c974"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/BCTrade-Btc_with_indicators_1641756030_ef1c6fd3?wsid=/subscriptions/736ac584-c533-43a9-8a83-d19bf290ffb8/resourcegroups/ml-rg/workspaces/ml-workspace&tid=3ffbf2df-6ac2-41dc-95c5-2f64a8024caf\", \"run_id\": \"BCTrade-Btc_with_indicators_1641756030_ef1c6fd3\", \"run_properties\": {\"run_id\": \"BCTrade-Btc_with_indicators_1641756030_ef1c6fd3\", \"created_utc\": \"2022-01-09T19:20:34.604767Z\", \"properties\": {}, \"tags\": {}, \"end_time_utc\": \"2022-01-09T19:22:45.487771Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/reinforcementlearning.txt\": \"https://rnikolaus.blob.core.windows.net/azureml/ExperimentRun/dcid.BCTrade-Btc_with_indicators_1641756030_ef1c6fd3/azureml-logs/reinforcementlearning.txt?sv=2019-07-07&sr=b&sig=7%2FOrDXRzRcRViI4oMaacJkvRexVcAmOYFJwY4pmNzF4%3D&skoid=e2479b93-fc73-41fb-89ce-5cfc3e486410&sktid=3ffbf2df-6ac2-41dc-95c5-2f64a8024caf&skt=2022-01-09T18%3A34%3A42Z&ske=2022-01-11T02%3A44%3A42Z&sks=b&skv=2019-07-07&st=2022-01-09T19%3A27%3A08Z&se=2022-01-10T03%3A37%3A08Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/reinforcementlearning.txt\"]], \"run_duration\": \"0:02:10\", \"run_number\": \"19\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"BCTrade-Btc_with_indicators_1641756030_ef1c6fd3_head\", \"run_number\": 20, \"metric\": null, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2022-01-09T19:20:57.276015Z\", \"end_time\": \"2022-01-09T19:22:44.650547Z\", \"created_time\": \"2022-01-09T19:20:41.859176Z\", \"created_time_dt\": \"2022-01-09T19:20:41.859176Z\", \"duration\": \"0:02:02\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2022-01-09T19:20:34.8685895Z][Info]Starting reinforcement learning run with id BCTrade-Btc_with_indicators_1641756030_ef1c6fd3.\\n[2022-01-09T19:20:40.5239892Z][Info]Starting head node child run with id BCTrade-Btc_with_indicators_1641756030_ef1c6fd3_head.\\n[2022-01-09T19:22:47.9705269Z][Info]Some child runs have reached terminal state. All active child runs will be cancelled. The run Ids that reached terminal state are: BCTrade-Btc_with_indicators_1641756030_ef1c6fd3_head.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.36.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'log_files'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipywidgets/widgets/widget.py\u001b[0m in \u001b[0;36m_handle_msg\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    674\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'buffer_paths'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                     \u001b[0m_put_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'buffer_paths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'buffers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;31m# Handle a state request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipywidgets/widgets/widget.py\u001b[0m in \u001b[0;36mset_state\u001b[0;34m(self, sync_data)\u001b[0m\n\u001b[1;32m    543\u001b[0m                     from_json = self.trait_metadata(name, 'from_json',\n\u001b[1;32m    544\u001b[0m                                                     self._trait_from_json)\n\u001b[0;32m--> 545\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msync_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mhold_trait_notifications\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchanges\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mchange\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchanges\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_notify_trait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipywidgets/widgets/widget.py\u001b[0m in \u001b[0;36mnotify_change\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m    604\u001b[0m                 \u001b[0;31m# Send new state to front-end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWidget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mnotify_change\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m   1174\u001b[0m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0mc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_notifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/widgets/_userrun/_run_details.py\u001b[0m in \u001b[0;36m_on_selected_run_log_change\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_on_selected_run_log_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_run_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m         self._get_run_logs_async(self.widget_instance.run_properties['log_files'],\n\u001b[0m\u001b[1;32m    625\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidget_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_properties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                                  self.error, change.new)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'log_files'"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1641756088179
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wait for completion of the rollout run before moving to the next section, or you may cancel the run."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment line below to cancel the run\n",
        "#rollout_run.cancel()\n",
        "rollout_run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "{'runId': 'BCTrade_1640904104_262fc15a',\n 'status': 'Finalizing',\n 'startTimeUtc': '2021-12-30T22:42:23.225849Z',\n 'services': {},\n 'properties': {},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'logFiles': {'azureml-logs/reinforcementlearning.txt': 'https://rnikolaus.blob.core.windows.net/azureml/ExperimentRun/dcid.BCTrade_1640904104_262fc15a/azureml-logs/reinforcementlearning.txt?sv=2019-07-07&sr=b&sig=NmkQMKN%2B7cgcPyuy0rRIsiohVyuPLutuSshX%2F7b1CQs%3D&skoid=e2479b93-fc73-41fb-89ce-5cfc3e486410&sktid=3ffbf2df-6ac2-41dc-95c5-2f64a8024caf&skt=2021-12-30T12%3A18%3A27Z&ske=2021-12-31T20%3A28%3A27Z&sks=b&skv=2019-07-07&st=2021-12-30T22%3A32%3A05Z&se=2021-12-31T06%3A42%3A05Z&sp=r'},\n 'submittedBy': 'Raphael Nikolaus'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1640904270550
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display movies of selected rollout episodes\n",
        "\n",
        "To display recorded movies first we download recorded videos to local machine. Here again we create a dataset of rollout artifacts and use the helper functions introduced above to download and displays rollout videos."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to child run\n",
        "child_runs = list(rollout_run.get_children())\n",
        "print('Number of child runs:', len(child_runs))\n",
        "child_run_0 = child_runs[0]\n",
        "\n",
        "# Download rollout artifacts\n",
        "rollout_artifacts_path = path.join(\"logs\", \"rollout\")\n",
        "print(\"Rollout artifacts path:\", rollout_artifacts_path)\n",
        "\n",
        "if path.exists(rollout_artifacts_path):\n",
        "    dir_util.remove_tree(rollout_artifacts_path)\n",
        "\n",
        "# Download videos to local compute\n",
        "child_run_0.download_files(\"logs/video\", output_directory = rollout_artifacts_path)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1640436763220
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning up\n",
        "For your convenience, below you can find code snippets to clean up any resources created as part of this tutorial that you don't wish to retain."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# To archive the created experiment:\n",
        "#exp.archive()\n",
        "\n",
        "# To delete the compute target:\n",
        "#compute_target.delete()\n",
        "\n",
        "# To delete downloaded training artifacts\n",
        "#if os.path.exists(training_artifacts_path):\n",
        "#    dir_util.remove_tree(training_artifacts_path)\n",
        "\n",
        "# To delete downloaded rollout videos\n",
        "#if path.exists(rollout_artifacts_path):\n",
        "#    dir_util.remove_tree(rollout_artifacts_path)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1640434365789
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next\n",
        "This example was about running Reinforcement Learning in Azure Machine Learning (Ray/RLlib Framework) on a single compute. Please see [Pong Problem](../atari-on-distributed-compute/pong_rllib.ipynb)\n",
        "example which uses Ray RLlib to train a Pong playing agent on a multi-node cluster."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "hoazari"
      },
      {
        "name": "dasommer"
      }
    ],
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "notice": "Copyright (c) Microsoft Corporation. All rights reserved. Licensed under the MIT License.",
    "categories": [
      "how-to-use-azureml",
      "reinforcement-learning"
    ],
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}